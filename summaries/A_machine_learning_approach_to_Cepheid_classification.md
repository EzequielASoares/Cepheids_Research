# ğŸ“Œ A Machine Learning Approach to Cepheid Variable Star Classification
**Resumo detalhado do artigo: a machine learning approach to cepheid variable stars classification using data alignment and maximum likelihood.**  

---

## **1ï¸âƒ£ Abstract - Resumo Geral**
Este artigo propÃµe um mÃ©todo baseado em aprendizado de mÃ¡quina para classificar **Cefeidas** em duas categorias:  
âœ”ï¸ **Modo Fundamental**  
âœ”ï¸ **Primeiro HarmÃ´nico**  

A classificaÃ§Ã£o se torna desafiadora quando aplicamos um modelo treinado em uma **galÃ¡xia prÃ³xima (LMC - Grande Nuvem de MagalhÃ£es)** a uma **galÃ¡xia distante (M33)** devido a:  
- **MudanÃ§a na magnitude aparente** â€“ Cefeidas mais fracas tornam-se indetectÃ¡veis.  
- **ViÃ©s amostral** â€“ A proporÃ§Ã£o de estrelas mais luminosas aumenta na galÃ¡xia-alvo.  

O artigo propÃµe um mÃ©todo de **alinhamento de dados via mÃ¡xima verossimilhanÃ§a** para corrigir essas diferenÃ§as e permitir a reutilizaÃ§Ã£o de um modelo treinado sem necessidade de re-rotulagem manual dos dados.  

---

## **2ï¸âƒ£ IntroduÃ§Ã£o**
- A relaÃ§Ã£o **PerÃ­odo-Luminosidade (P-L)** Ã© fundamental para medir distÃ¢ncias astronÃ´micas.  
- A mudanÃ§a na distribuiÃ§Ã£o dos dados entre galÃ¡xias dificulta a aplicaÃ§Ã£o direta de um modelo treinado.  
- O artigo propÃµe um mÃ©todo para alinhar os dados da **M33** aos da **LMC** antes de aplicar a classificaÃ§Ã£o.  

### **ğŸ“Œ Principais desafios abordados**
âœ”ï¸ **MudanÃ§a sistemÃ¡tica na magnitude** devido Ã  distÃ¢ncia.  
âœ”ï¸ **Dificuldade de identificar as classes corretas das Cefeidas sem novos rÃ³tulos.**  
âœ”ï¸ **AdaptaÃ§Ã£o do modelo sem precisar de um novo treinamento.**  

---

## **3ï¸âƒ£ Conceitos Preliminares**
### **ğŸ“Œ VariÃ¡veis Cefeidas**
As **Cefeidas ClÃ¡ssicas** sÃ£o estrelas pulsantes cuja **luminosidade varia periodicamente** de acordo com a seguinte equaÃ§Ã£o:  

$$
\log_{10} L = a + b \cdot \log_{10} P
$$

Onde:  
- **\(L\)** â†’ Luminosidade da estrela.  
- **\(P\)** â†’ PerÃ­odo de oscilaÃ§Ã£o.  
- **\(a, b\)** â†’ ParÃ¢metros da relaÃ§Ã£o PerÃ­odo-Luminosidade.  

A **magnitude aparente** ($m$) de uma estrela Ã© dada por:

$$
m = -2.5 \cdot \log_{10} \left(\frac{L}{d^2}\right)
$$

Onde **\(d\)** Ã© a distÃ¢ncia atÃ© a estrela. Assim, **quanto menor o valor de \(m\), mais brilhante a estrela aparece**.  

---

## **4ï¸âƒ£ Metodologia**
A abordagem do artigo envolve **duas etapas principais**:  

### **ğŸ“Œ 1. Ajuste da Magnitude por MÃ¡xima VerossimilhanÃ§a**
O primeiro passo Ã© encontrar um **deslocamento** $\delta$ na magnitude aparente para alinhar os dados da M33 aos da LMC.  

$$
x'_2 = x_2 + \delta
$$

O deslocamento $\delta$ Ã© encontrado **maximizando a verossimilhanÃ§a** dos dados da M33 em relaÃ§Ã£o Ã  distribuiÃ§Ã£o das Cefeidas na LMC:  

$$
L(\delta | T_{te}') = \sum_{k=1}^{q} \log P_{tr}(x_k)
$$

Aqui, **$P_{tr}(x)$** representa a distribuiÃ§Ã£o de probabilidade das Cefeidas na LMC, assumida como uma **mistura de duas distribuiÃ§Ãµes Gaussianas**:  

$$
P_{tr}(x_1, x_2) = \sum_{i=1}^{2} \phi_i \frac{1}{2\pi\sigma_{i1}\sigma_{i2} \sqrt{1 - \rho_i^2}} \exp\left(-\frac{v_i}{2(1 - \rho_i^2)}\right)
$$

Onde os parÃ¢metros **$\mu_i, \sigma_i, \phi_i$** sÃ£o ajustados pelos dados da LMC.

### **ğŸ“Œ 2. Refinamento do Ajuste Baseado na ProporÃ§Ã£o das Classes**
ApÃ³s encontrar $\delta$, ajustamos iterativamente sua magnitude atÃ© que a proporÃ§Ã£o das classes prevista no conjunto de teste **coincida com a distribuiÃ§Ã£o original da LMC**. Isso Ã© feito aplicando **bootstrap** para estimar a proporÃ§Ã£o esperada das classes.  

---

## **5ï¸âƒ£ Resultados Experimentais**
Os experimentos avaliaram a **precisÃ£o da classificaÃ§Ã£o** em duas bandas:  
âœ”ï¸ **Banda VisÃ­vel (V)**  
âœ”ï¸ **Banda Infravermelha (I)**  

### **ğŸ“Œ ComparaÃ§Ã£o de PrecisÃ£o (%)**
| MÃ©todo | Sem correÃ§Ã£o | Deslocamento fixo | Passo 1 (VerossimilhanÃ§a) | Passo 2 (Refinamento) |
|--------|------------|----------------|-------------------|----------------|
| **Redes Neurais** | 90,09% | 94,48% | **96,78%** | 95,72% |
| **SVM** | 93,38% | 95,30% | 95,98% | **97,09%** |
| **Ãrvores de DecisÃ£o** | 94,32% | 94,49% | 97,27% | **97,09%** |
| **Random Forest** | 94,12% | 94,80% | 96,13% | **96,40%** |

---

## **6ï¸âƒ£ ConclusÃ£o**
- A tÃ©cnica permite reutilizar um modelo treinado sem necessidade de rotulagem manual dos dados da galÃ¡xia-alvo.  
- O mÃ©todo melhora a precisÃ£o e supera abordagens anteriores baseadas em **deslocamento fixo**.  
- Pode ser aplicada em outras Ã¡reas onde hÃ¡ **mudanÃ§as sistemÃ¡ticas nos dados**, como **fÃ­sica de partÃ­culas e aprendizado por transferÃªncia (transfer learning)**.  

---

## **ğŸ“Œ Pontos Positivos e Negativos da Reprodutibilidade**
### **âœ”ï¸ Pontos Positivos**
âœ… O mÃ©todo utiliza conceitos estatÃ­sticos bem estabelecidos.  
âœ… NÃ£o exige novas rotulaÃ§Ãµes manuais, reduzindo o custo da classificaÃ§Ã£o.  
âœ… Pode ser aplicado a outras Ã¡reas com problemas similares de deslocamento de dados.  

### **âŒ Pontos Negativos**
âŒ Depende de uma boa modelagem da distribuiÃ§Ã£o inicial.  
âŒ A precisÃ£o pode ser afetada por ruÃ­dos na mediÃ§Ã£o das magnitudes.  
âŒ O processo de ajuste pode ser computacionalmente caro.  
